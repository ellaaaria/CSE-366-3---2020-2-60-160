{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment-1: Enhanced Dynamic Robot Movement Simulation**"
      ],
      "metadata": {
        "id": "hC6g6T-J6VV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import heapq\n",
        "\n",
        "class PriorityQueue:\n",
        "    def __init__(self):\n",
        "        self.elements = []\n",
        "\n",
        "    def empty(self):\n",
        "        return len(self.elements) == 0\n",
        "\n",
        "    def put(self, item, priority):\n",
        "        heapq.heappush(self.elements, (priority, item))\n",
        "\n",
        "    def get(self):\n",
        "        return heapq.heappop(self.elements)[1]\n",
        "\n",
        "\n",
        "# Node Class represents a state in the search tree.\n",
        "class Node:\n",
        "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
        "        self.state = state  # The current position of the agent in the grid.\n",
        "        self.parent = parent  # The node in the search tree that generated this node.\n",
        "        self.action = action  # The action taken to get to this state.\n",
        "        self.path_cost = path_cost  # Cost from the start node to this node.\n",
        "\n",
        "    # Comparison operator for priority queue.\n",
        "    def __lt__(self, other):\n",
        "        return self.path_cost < other.path_cost\n"
      ],
      "metadata": {
        "id": "iTFcWD1f7cgk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic(a, b):\n",
        "    \"\"\"\n",
        "    Calculate the Manhattan distance between two points a and b.\n",
        "\n",
        "    Parameters:\n",
        "    - a: Tuple representing the x and y coordinates of point a (e.g., (x1, y1))\n",
        "    - b: Tuple representing the x and y coordinates of point b (e.g., (x2, y2))\n",
        "\n",
        "    Returns:\n",
        "    - The Manhattan distance between points a and b.\n",
        "    \"\"\"\n",
        "    (x1, y1) = a\n",
        "    (x2, y2) = b\n",
        "    return abs(x1 - x2) + abs(y1 - y2)\n"
      ],
      "metadata": {
        "id": "ppYXyDGh7tTA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Env***"
      ],
      "metadata": {
        "id": "oFG1tMF_7z2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Class represents the grid and handles state transitions.\n",
        "class Environment:\n",
        "    def __init__(self, grid, start, goal):\n",
        "        self.grid = grid  # The grid layout where 1 represents an obstacle and 0 is free space.\n",
        "        self.initial = start  # Starting position of the agent.\n",
        "        self.goal = goal  # Goal position the agent aims to reach.\n",
        "        self.battery_level = 100  # Battery level starts at 100%\n",
        "        self.recharge_count = 0  # Initialize recharge count to 0.\n",
        "\n",
        "\n",
        "\n",
        "    # Returns the possible actions from a given state.\n",
        "    def actions(self, state):\n",
        "        possible_actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
        "        x, y = state\n",
        "\n",
        "        # Remove impossible actions based on grid boundaries and obstacles.\n",
        "        if x == 0 or self.grid[x - 1][y] == 1:\n",
        "            possible_actions.remove('UP')\n",
        "        if x == len(self.grid) - 1 or self.grid[x + 1][y] == 1:\n",
        "            possible_actions.remove('DOWN')\n",
        "        if y == 0 or self.grid[x][y - 1] == 1:\n",
        "            possible_actions.remove('LEFT')\n",
        "        if y == len(self.grid[0]) - 1 or self.grid[x][y + 1] == 1:\n",
        "            possible_actions.remove('RIGHT')\n",
        "\n",
        "        return possible_actions\n",
        "\n",
        "    # Returns the state resulting from taking a given action at a given state.\n",
        "    def result(self, state, action):\n",
        "        x, y = state\n",
        "\n",
        "        if action == 'UP':\n",
        "            new_state = (x - 1, y)\n",
        "        elif action == 'DOWN':\n",
        "            new_state = (x + 1, y)\n",
        "        elif action == 'LEFT':\n",
        "            new_state = (x, y - 1)\n",
        "        elif action == 'RIGHT':\n",
        "            new_state = (x, y + 1)\n",
        "\n",
        "        # Update battery level\n",
        "        self.battery_level -= 10\n",
        "        if self.battery_level <= 0:\n",
        "            # Robot must recharge before continuing\n",
        "            self.recharge_battery()\n",
        "\n",
        "        return new_state\n",
        "\n",
        "\n",
        "\n",
        "    # Recharges the battery level to 100%.\n",
        "    def recharge_battery(self):\n",
        "        self.battery_level = 100\n",
        "        self.recharge_count += 1\n",
        "\n",
        "    # Checks if the goal has been reached.\n",
        "    def is_goal(self, state):\n",
        "        return state == self.goal\n",
        "\n",
        "    # Returns the current recharge count.\n",
        "    def get_recharge_count(self):\n",
        "        return self.recharge_count"
      ],
      "metadata": {
        "id": "YwfW5yv971jX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***agent***"
      ],
      "metadata": {
        "id": "fEKMNXEU8SKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "\n",
        "    # Performs Uniform Cost Search to find the lowest cost path from the initial state to the goal.\n",
        "    def uniform_cost_search(self):\n",
        "        frontier = PriorityQueue()  # Priority queue for UCS.\n",
        "        frontier.put(Node(self.env.initial, path_cost=0), 0)\n",
        "        came_from = {self.env.initial: None}\n",
        "        cost_so_far = {self.env.initial: 0}\n",
        "\n",
        "        while not frontier.empty():\n",
        "            current_node = frontier.get()\n",
        "\n",
        "            if self.env.is_goal(current_node.state):\n",
        "                return self.reconstruct_path(came_from, current_node.state)\n",
        "\n",
        "            for action in self.env.actions(current_node.state):\n",
        "                new_state = self.env.result(current_node.state, action)\n",
        "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity; adjust if varying costs.\n",
        "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
        "                    cost_so_far[new_state] = new_cost\n",
        "                    priority = new_cost\n",
        "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
        "                    came_from[new_state] = current_node.state\n",
        "\n",
        "        return []\n",
        "\n",
        "\n",
        "    def a_star_search(self):\n",
        "        # The start node is created with a path cost of 0.\n",
        "        start_node = Node(self.env.initial, path_cost=0)\n",
        "        frontier = PriorityQueue()\n",
        "        frontier.put(start_node, 0)  # Priority is f-cost, initially the heuristic cost from start to goal\n",
        "        came_from = {self.env.initial: None}  # Tracks the best path to a node\n",
        "        cost_so_far = {self.env.initial: 0}  # Tracks the g-cost (cost so far to reach a node)\n",
        "\n",
        "        while not frontier.empty():\n",
        "            current_node = frontier.get()\n",
        "\n",
        "            if self.env.is_goal(current_node.state):\n",
        "                return self.reconstruct_path(came_from, current_node.state)\n",
        "\n",
        "            for action in self.env.actions(current_node.state):\n",
        "                new_state = self.env.result(current_node.state, action)\n",
        "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity\n",
        "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
        "                    cost_so_far[new_state] = new_cost\n",
        "                    priority = new_cost + heuristic(new_state, self.env.goal)  # f-cost = g-cost + h-cost\n",
        "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
        "                    came_from[new_state] = current_node.state\n",
        "\n",
        "        return []\n",
        "\n",
        "    def reconstruct_path(self, came_from, current):\n",
        "        path = []\n",
        "        while current in came_from:\n",
        "            path.append(current)\n",
        "            current = came_from[current]\n",
        "        path.append(self.env.initial)  # Start node is not in came_from\n",
        "        path.reverse()  # Reverse to get the path from start to goal\n",
        "        return path\n"
      ],
      "metadata": {
        "id": "TzhHTpXG8UAj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Visualization Function plots the grid and the found path.***"
      ],
      "metadata": {
        "id": "I9mh0UOd79Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization Function plots the grid and the found path.\n",
        "def visualize_grid_and_path(grid, path):\n",
        "    grid_array = np.array(grid)  # Convert grid to numpy array for easy plotting.\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(grid_array, cmap='Greys', alpha=0.3)  # Grid background.\n",
        "    start = path[0]\n",
        "    goal = path[-1]\n",
        "    ax.plot(start[1], start[0], 'bs', markersize=10)  # Start position in blue.\n",
        "    ax.plot(goal[1], goal[0], 'gs', markersize=10)  # Goal position in green.\n",
        "    xs, ys = zip(*path)  # Extract X and Y coordinates of the path.\n",
        "    ax.plot(ys, xs, 'r-', linewidth=2)  # Plot the path in red.\n",
        "    ax.set_xticks(np.arange(-.5, len(grid[0]), 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, len(grid), 1), minor=True)\n",
        "    ax.grid(which=\"minor\", color=\"b\", linestyle='-', linewidth=1)\n",
        "    ax.tick_params(which=\"minor\", size=0)\n",
        "    ax.tick_params(which=\"major\", bottom=False, left=False, labelbottom=False, labelleft=False)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HY42fL8K7_Jb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***# Define the grid, start position, and goal position***"
      ],
      "metadata": {
        "id": "GtVByBhY--AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the grid, start position, and goal position\n",
        "grid = [\n",
        "    [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
        "    [0, 1, 0, 1, 0, 1, 0, 0 ,0, 1],\n",
        "    [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "    [0, 0, 0, 1, 1, 1, 1, 0, 1, 0],\n",
        "    [0, 1, 0, 0, 0, 1, 1, 0, 1, 0],\n",
        "    [0, 1, 0, 1, 0, 0, 0, 1, 0, 1],\n",
        "    [0, 1, 0, 0, 0, 1, 0, 1, 0, 1],\n",
        "    [0, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n",
        "    [0, 1, 0, 0, 0, 1, 1, 1, 0, 1],\n",
        "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
        "]\n",
        "\n",
        "start = (0, 0)\n",
        "goal = (9, 9)\n",
        "# Generate a Random Grid Function\n",
        "def generate_random_grid(size, obstacle_probability):\n",
        "    return np.random.choice([0, 1], size=(size, size), p=[1-obstacle_probability, obstacle_probability])\n",
        "\n",
        "# Define the size of the grid and the probability of an obstacle in each cell\n",
        "grid_size = 10\n",
        "obstacle_probability = 0.2  # 20% chance of being an obstacle\n",
        "\n",
        "# Generate a random grid\n",
        "grid = generate_random_grid(grid_size, obstacle_probability)\n",
        "\n",
        "# Define start and goal positions\n",
        "start = (0, 0)\n",
        "goal = (grid_size - 1, grid_size - 1)\n",
        "\n",
        "# Ensure start and goal are not obstacles\n",
        "grid[start] = 0\n",
        "grid[goal] = 0\n",
        "\n",
        "# Create the environment and agent for Uniform Cost Search\n",
        "environment_for_ucs = Environment(grid, start, goal)\n",
        "agent = Agent(environment_for_ucs)\n",
        "\n",
        "\n",
        "# Solve the problem with Uniform Cost Search\n",
        "solution_path_ucs = agent.uniform_cost_search()\n",
        "recharge_count_ucs = environment_for_ucs.get_recharge_count()\n",
        "print(\"UCS Solution Path:\", solution_path_ucs)\n",
        "print(\"UCS Recharge Count:\", recharge_count_ucs)\n",
        "\n",
        "\n",
        "# Create the environment and agent for A* algorithm\n",
        "environment_for_astar = Environment(grid, start, goal)\n",
        "agent = Agent(environment_for_astar)\n",
        "\n",
        "\n",
        "# Solve the problem with the A* algorithm\n",
        "solution_path_astar = agent.a_star_search()\n",
        "recharge_count_astar = environment_for_astar.get_recharge_count()\n",
        "print(\"A* Solution Path:\", solution_path_astar)\n",
        "print(\"A* Recharge Count:\", recharge_count_astar)\n",
        "\n",
        "# Compare recharge counts and determine the best algorithm\n",
        "if recharge_count_ucs < recharge_count_astar:\n",
        "    print(\"Uniform Cost Search is more efficient in terms of energy management.\")\n",
        "elif recharge_count_astar < recharge_count_ucs:\n",
        "    print(\"A* Search is more efficient in terms of energy management.\")\n",
        "else:\n",
        "    print(\"Both algorithms have the same efficiency in terms of energy management.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Visualize the solution\n",
        "visualize_grid_and_path(grid, solution_path_ucs)\n",
        "visualize_grid_and_path(grid, solution_path_astar)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "DaQ5m6UL_CfN",
        "outputId": "999cf869-c7b9-44c7-e548-46ef17a3a6cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UCS Solution Path: [(0, 0), (0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (5, 1), (6, 1), (6, 2), (6, 3), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9)]\n",
            "UCS Recharge Count: 23\n",
            "A* Solution Path: [(0, 0), (0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (5, 1), (6, 1), (6, 2), (6, 3), (7, 3), (8, 3), (9, 3), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9)]\n",
            "A* Recharge Count: 22\n",
            "A* Search is more efficient in terms of energy management.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}